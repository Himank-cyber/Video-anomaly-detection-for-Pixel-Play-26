{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2215958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "INPUT_ROOT = \"Avenue_Corrupted-20251221T112159Z-3-001\\Avenue_Corrupted\\Dataset\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b46fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "\n",
    "OUTPUT_ROOT_DATASET = \"cleaned_data\"\n",
    "\n",
    "\n",
    "def fix_dataset(input_dir, output_dir, is_testing=False):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    folders = sorted(os.listdir(input_dir))\n",
    "    \n",
    "    print(f\"Cleaning {len(folders)} folders in {'TESTING' if is_testing else 'TRAINING'} mode...\")\n",
    "\n",
    "    for folder in folders:\n",
    "        in_path = os.path.join(input_dir, folder)\n",
    "        out_path = os.path.join(output_dir, folder)\n",
    "        \n",
    "        if not os.path.isdir(in_path): continue\n",
    "            \n",
    "        os.makedirs(out_path, exist_ok=True)\n",
    "        frames = sorted(glob.glob(os.path.join(in_path, \"*.jpg\")))\n",
    "        \n",
    "        last_valid_blur = None # Memory of the last good frame\n",
    "\n",
    "        # Check if this is one of the \"Bad Start\" clips (13 or 19)\n",
    "        # We check both \"13\" and \"19\" strings to be safe\n",
    "        is_bad_start = is_testing and (folder in ['13', '19'] or folder.endswith('13') or folder.endswith('19'))\n",
    "\n",
    "        for frame_path in tqdm(frames, desc=f\"Folder {folder}\", leave=False):\n",
    "            img = cv2.imread(frame_path)\n",
    "            if img is None: continue\n",
    "            filename = os.path.basename(frame_path)\n",
    "\n",
    "            # --- 1. FIX UPSIDE DOWN FRAMES (Test Set Only) ---\n",
    "            if is_testing:\n",
    "                # We blur the image A LOT to see big shapes (head, body)\n",
    "                curr_blur = cv2.medianBlur(img, 11)\n",
    "                \n",
    "                if last_valid_blur is None:\n",
    "                    # SPECIAL RULE: If it's Clip 13 or 19, the first frame is wrong.\n",
    "                    if is_bad_start:\n",
    "                        img = cv2.flip(img, 0)       # Flip the real image\n",
    "                        curr_blur = cv2.flip(curr_blur, 0) # Flip our memory anchor\n",
    "                    \n",
    "                    last_valid_blur = curr_blur # Set this as the standard for the next frame\n",
    "                else:\n",
    "                    flipped_blur = cv2.flip(curr_blur, 0)\n",
    "                    \n",
    "                    # Compare: Is the Normal or Flipped version closer to the last frame?\n",
    "                    diff_normal = np.mean((curr_blur - last_valid_blur) ** 2)\n",
    "                    diff_flipped = np.mean((flipped_blur - last_valid_blur) ** 2)\n",
    "                    \n",
    "                    # If the flipped version is significantly better, use it\n",
    "                    if diff_flipped < diff_normal:\n",
    "                        img = cv2.flip(img, 0) # Flip the REAL image\n",
    "                        last_valid_blur = flipped_blur\n",
    "                    else:\n",
    "                        last_valid_blur = curr_blur\n",
    "\n",
    "            # --- 2. CLEAN THE NOISE (All Sets) ---\n",
    "            # This filter removes the colored speckles\n",
    "            img = cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)\n",
    "\n",
    "            # Save the clean frame\n",
    "            cv2.imwrite(os.path.join(out_path, filename), img)\n",
    "\n",
    "# RUN THE CLEANER\n",
    "# 1. Clean Training Data\n",
    "fix_dataset(os.path.join(INPUT_ROOT, \"training_videos\"), \n",
    "            os.path.join(OUTPUT_ROOT_DATASET, \"training_videos\"), is_testing=False)\n",
    "\n",
    "# 2. Clean Testing Data\n",
    "fix_dataset(os.path.join(INPUT_ROOT, \"testing_videos\"), \n",
    "            os.path.join(OUTPUT_ROOT_DATASET, \"testing_videos\"), is_testing=True)\n",
    "\n",
    "\n",
    "TEST_DIR =  os.path.join(OUTPUT_ROOT_DATASET, \"testing_videos\")\n",
    "\n",
    "print(\"ALL DATA CLEANED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ababb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, Input\n",
    "\n",
    "def build_unet():\n",
    "    # We take 4 frames of history (stacked together, so 12 channels)\n",
    "    inputs = Input(shape=(256, 256, 12)) \n",
    "    \n",
    "    # --- ENCODER (Squishing down) ---\n",
    "    c1 = layers.Conv2D(64, 3, padding='same', activation='relu')(inputs)\n",
    "    c1 = layers.Conv2D(64, 3, padding='same', activation='relu')(c1)\n",
    "    p1 = layers.MaxPooling2D()(c1)\n",
    "    \n",
    "    c2 = layers.Conv2D(128, 3, padding='same', activation='relu')(p1)\n",
    "    c2 = layers.Conv2D(128, 3, padding='same', activation='relu')(c2)\n",
    "    p2 = layers.MaxPooling2D()(c2)\n",
    "    \n",
    "    c3 = layers.Conv2D(256, 3, padding='same', activation='relu')(p2)\n",
    "    c3 = layers.Conv2D(256, 3, padding='same', activation='relu')(c3)\n",
    "    p3 = layers.MaxPooling2D()(c3)\n",
    "    \n",
    "    # --- BOTTLENECK (The deepest part) ---\n",
    "    c4 = layers.Conv2D(512, 3, padding='same', activation='relu')(p3)\n",
    "    c4 = layers.Conv2D(512, 3, padding='same', activation='relu')(c4)\n",
    "    \n",
    "    # --- DECODER (Building back up) ---\n",
    "    u1 = layers.Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(c4)\n",
    "    u1 = layers.concatenate([u1, c3]) # Skip connection!\n",
    "    c5 = layers.Conv2D(256, 3, padding='same', activation='relu')(u1)\n",
    "    c5 = layers.Conv2D(256, 3, padding='same', activation='relu')(c5)\n",
    "    \n",
    "    u2 = layers.Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(c5)\n",
    "    u2 = layers.concatenate([u2, c2])\n",
    "    c6 = layers.Conv2D(128, 3, padding='same', activation='relu')(u2)\n",
    "    c6 = layers.Conv2D(128, 3, padding='same', activation='relu')(c6)\n",
    "    \n",
    "    u3 = layers.Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(c6)\n",
    "    u3 = layers.concatenate([u3, c1])\n",
    "    c7 = layers.Conv2D(64, 3, padding='same', activation='relu')(u3)\n",
    "    c7 = layers.Conv2D(64, 3, padding='same', activation='relu')(c7)\n",
    "    \n",
    "    # Final prediction (1 frame, 3 channels RGB)\n",
    "    outputs = layers.Conv2D(3, 3, padding='same', activation='tanh')(c7)\n",
    "    \n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "ai_brain = build_unet()\n",
    "print(\"Brain built!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c32b10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_discriminator(input_shape=(256, 256, 3)):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    def downsample(filters, size, apply_batchnorm=True):\n",
    "        result = tf.keras.Sequential()\n",
    "        result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                                          kernel_initializer=initializer, use_bias=False))\n",
    "        if apply_batchnorm:\n",
    "            result.add(tf.keras.layers.BatchNormalization())\n",
    "        result.add(tf.keras.layers.LeakyReLU())\n",
    "        return result\n",
    "\n",
    "    x = downsample(64, 4, apply_batchnorm=False)(inputs) # (128, 128, 64)\n",
    "    f1 = downsample(128, 4)(x)                           # (64, 64, 128) -> FEATURE LAYER 1\n",
    "    f2 = downsample(256, 4)(f1)                          # (32, 32, 256) -> FEATURE LAYER 2\n",
    "    f3 = downsample(512, 4)(f2)                          # (16, 16, 512)\n",
    "    \n",
    "    output = tf.keras.layers.Conv2D(1, 4, strides=1, padding='same',\n",
    "                                    kernel_initializer=initializer)(f3) \n",
    "    \n",
    "    # Return Output AND Intermediate Features\n",
    "    return tf.keras.Model(inputs=inputs, outputs=[output, f1, f2], name=\"Feature_Discriminator\")\n",
    "\n",
    "ai_discriminator = build_feature_discriminator()\n",
    "print(\"Feature Matching Discriminator Built!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6433b402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "# --- 1. LOSS FUNCTIONS (Feature Matching + Motion) ---\n",
    "\n",
    "def ohem_loss(predicted, target):\n",
    "    \"\"\"\n",
    "    Online Hard Example Mining (OHEM).\n",
    "    Instead of averaging ALL pixels, we only take the mean of the \n",
    "    WORST 10% of pixels. This forces the model to fix the anomalies.\n",
    "    \"\"\"\n",
    "    # 1. Calculate absolute error per pixel\n",
    "    abs_error = tf.abs(predicted - target)\n",
    "    \n",
    "    # 2. Flatten the errors to a 1D list\n",
    "    # Shape: [Batch_Size * 256 * 256 * 3]\n",
    "    flat_errors = tf.reshape(abs_error, [-1])\n",
    "    \n",
    "    # 3. Find the Top K (Worst 10% of errors)\n",
    "    # Total pixels per batch\n",
    "    k = tf.cast(tf.shape(flat_errors)[0], tf.float32) * 0.10 \n",
    "    k = tf.cast(k, tf.int32)\n",
    "    \n",
    "    # Get the worst values\n",
    "    worst_errors, _ = tf.math.top_k(flat_errors, k=k)\n",
    "    \n",
    "    # 4. Return the mean of ONLY the worst errors\n",
    "    return tf.reduce_mean(worst_errors)\n",
    "\n",
    "def feature_matching_loss(real_feats, fake_feats):\n",
    "    \"\"\"\n",
    "    Forces the Generator to match the internal features of the Discriminator.\n",
    "    This stabilizes training significantly.\n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    for r, f in zip(real_feats, fake_feats):\n",
    "        loss += tf.reduce_mean(tf.abs(r - f))\n",
    "    return loss\n",
    "\n",
    "def ssim_loss(predicted, target):\n",
    "    # Clip values to [-1, 1] to prevent NaN crashes\n",
    "    pred = tf.clip_by_value(predicted, -1.0, 1.0)\n",
    "    target = tf.clip_by_value(target, -1.0, 1.0)\n",
    "    return 1.0 - tf.reduce_mean(tf.image.ssim(pred, target, max_val=2.0))\n",
    "\n",
    "\n",
    "def get_total_generator_loss(predicted, target, d_fake_out, real_feats, fake_feats, last_history):\n",
    "    # Weights\n",
    "    LAM_INT = 1.0    \n",
    "    LAM_SSIM = 1.0   \n",
    "    LAM_GDL = 1.0    \n",
    "    LAM_ADV = 0.05   \n",
    "    LAM_FEAT = 1.0 \n",
    "    \n",
    "    # Standard Losses\n",
    "    l_int = ohem_loss(predicted, target)\n",
    "\n",
    "    l_ssim = ssim_loss(predicted, target)\n",
    "    \n",
    "    dy_pred, dx_pred = tf.image.image_gradients(predicted)\n",
    "    dy_true, dx_true = tf.image.image_gradients(target)\n",
    "    l_grad = tf.reduce_mean(tf.abs(tf.abs(dx_pred) - tf.abs(dx_true)) + \n",
    "                            tf.abs(tf.abs(dy_pred) - tf.abs(dy_true)))\n",
    "    \n",
    "    l_adv = 0.5 * tf.reduce_mean(tf.square(d_fake_out - 1.0))\n",
    "    l_feat = feature_matching_loss(real_feats, fake_feats)\n",
    "    \n",
    "    total_loss = (LAM_INT * l_int) + (LAM_SSIM * l_ssim) + \\\n",
    "                 (LAM_GDL * l_grad) + (LAM_ADV * l_adv) + (LAM_FEAT * l_feat)\n",
    "    \n",
    "    return total_loss, l_int, l_ssim, l_feat\n",
    "\n",
    "# --- 2. DATA GENERATOR (Standard) ---\n",
    "\n",
    "def train_generator():\n",
    "    train_path = os.path.join(OUTPUT_ROOT_DATASET, \"training_videos\")\n",
    "    folders = glob.glob(os.path.join(train_path, \"*\"))\n",
    "    \n",
    "    if not folders:\n",
    "        print(\"CRITICAL ERROR: No data found.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        folder = np.random.choice(folders)\n",
    "        files = sorted(glob.glob(os.path.join(folder, \"*.jpg\")))\n",
    "        if len(files) < 5: continue\n",
    "        idx = np.random.randint(0, len(files) - 5)\n",
    "        \n",
    "        # Random Flip (Augmentation)\n",
    "        flip_h = np.random.random() > 0.5\n",
    "        \n",
    "        history = []\n",
    "        for i in range(4):\n",
    "            img = cv2.imread(files[idx+i])\n",
    "            if img is None: continue\n",
    "            img = cv2.resize(img, (256, 256))\n",
    "            if flip_h: img = cv2.flip(img, 1)\n",
    "            img = (img / 127.5) - 1.0 \n",
    "            history.append(img)\n",
    "            \n",
    "        if len(history) < 4: continue\n",
    "        last_history_frame = history[-1]\n",
    "        history_stack = np.concatenate(history, axis=2)\n",
    "        \n",
    "        target = cv2.imread(files[idx+4])\n",
    "        if target is None: continue\n",
    "        target = cv2.resize(target, (256, 256))\n",
    "        if flip_h: target = cv2.flip(target, 1)\n",
    "        target = (target / 127.5) - 1.0\n",
    "        \n",
    "        yield (history_stack, target, last_history_frame)\n",
    "\n",
    "# --- 3. TRAINING SETUP ---\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    train_generator, \n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(256, 256, 12), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(256, 256, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(256, 256, 3), dtype=tf.float32)\n",
    "    )\n",
    ").batch(4).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Learning Rate Schedule\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=2e-4, decay_steps=5000, decay_rate=0.9, staircase=True\n",
    ")\n",
    "\n",
    "# Optimizers with Clipnorm (Stability)\n",
    "gen_optimizer = tf.keras.optimizers.Adam(lr_schedule, beta_1=0.5, clipnorm=1.0)\n",
    "disc_optimizer = tf.keras.optimizers.Adam(lr_schedule, beta_1=0.5, clipnorm=1.0)\n",
    "\n",
    "# Init Optimizers\n",
    "print(\"Initializing optimizer variables...\")\n",
    "if len(ai_discriminator.trainable_variables) > 0:\n",
    "    dummy_grads = [tf.zeros_like(w) for w in ai_discriminator.trainable_variables]\n",
    "    disc_optimizer.apply_gradients(zip(dummy_grads, ai_discriminator.trainable_variables))\n",
    "print(\"Optimizer Ready!\")\n",
    "\n",
    "@tf.function\n",
    "def train_step(history_batch, target_batch, last_hist_batch, use_gan=True):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_frame = ai_brain(history_batch, training=True)\n",
    "        \n",
    "        # Discriminator returns [Output, Feat1, Feat2]\n",
    "        d_real_out, r_f1, r_f2 = ai_discriminator(target_batch, training=True)\n",
    "        d_fake_out, f_f1, f_f2 = ai_discriminator(generated_frame, training=True)\n",
    "        \n",
    "        d_loss = 0.5 * (tf.reduce_mean(tf.square(d_real_out - 1.0)) + \n",
    "                        tf.reduce_mean(tf.square(d_fake_out)))\n",
    "        \n",
    "        # Calculate Total Loss\n",
    "        total_loss, l_int, l_ssim, l_feat = get_total_generator_loss(\n",
    "            generated_frame, target_batch, d_fake_out, \n",
    "            [r_f1, r_f2], [f_f1, f_f2], last_hist_batch\n",
    "        )\n",
    "        \n",
    "        if not use_gan:\n",
    "            # Remove adversarial components during warmup\n",
    "            total_loss = total_loss - (0.05 * 0.5 * tf.reduce_mean(tf.square(d_fake_out - 1.0)))\n",
    "\n",
    "    grad_gen = gen_tape.gradient(total_loss, ai_brain.trainable_variables)\n",
    "    gen_optimizer.apply_gradients(zip(grad_gen, ai_brain.trainable_variables))\n",
    "    \n",
    "    if use_gan:\n",
    "        grad_disc = disc_tape.gradient(d_loss, ai_discriminator.trainable_variables)\n",
    "        disc_optimizer.apply_gradients(zip(grad_disc, ai_discriminator.trainable_variables))\n",
    "    \n",
    "    return total_loss, d_loss, l_int, l_ssim, l_feat\n",
    "\n",
    "# --- 4. EXECUTION ---\n",
    "print(\"Starting Feature Matching Training...\")\n",
    "MAX_STEPS = 40000 \n",
    "WARMUP_STEPS = 2000 \n",
    "\n",
    "for step, (x_batch, y_batch, last_batch) in enumerate(dataset):\n",
    "    if step > MAX_STEPS: break\n",
    "    use_gan_now = (step > WARMUP_STEPS)\n",
    "    g_loss, d_loss, val_int, val_ssim, val_feat = train_step(x_batch, y_batch, last_batch, use_gan_now)\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        status = \"WARMUP\" if not use_gan_now else \"GAN\"\n",
    "        curr_lr = lr_schedule(step).numpy()\n",
    "        print(f\"Step {step} [{status}] LR:{curr_lr:.6f} | G_Loss:{g_loss:.4f} | Feat_Loss:{val_feat:.4f} | SSIM:{val_ssim:.4f}\")\n",
    "\n",
    "print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e06bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "OUTPUT_CSV = \"submission.csv\"\n",
    "NUM_HIS = 4\n",
    "\n",
    "def get_optical_flow_mask(prev_frame, curr_frame):\n",
    "    \"\"\"\n",
    "    Calculates Dense Optical Flow (Farneback).\n",
    "    Returns a mask where movement is happening.\n",
    "    \"\"\"\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    curr_gray = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate Flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, curr_gray, None, \n",
    "                                        0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    \n",
    "    # Calculate Magnitude (Speed of movement)\n",
    "    mag, _ = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    \n",
    "    # Normalize Magnitude to 0-1\n",
    "    mag = cv2.normalize(mag, None, 0, 1, cv2.NORM_MINMAX)\n",
    "    \n",
    "    # Threshold: Only consider significant movement\n",
    "    _, mask = cv2.threshold(mag, 0.2, 1.0, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Expand to 3 channels\n",
    "    return np.stack([mask]*3, axis=-1)\n",
    "\n",
    "def calculate_smart_psnr(pred, target, mask):\n",
    "    pred_0_1 = (pred + 1.0) / 2.0\n",
    "    target_0_1 = (target + 1.0) / 2.0\n",
    "    diff_sq = (target_0_1 - pred_0_1) ** 2\n",
    "    \n",
    "    # Weight foreground (mask) 1.0, background 0.05\n",
    "    weighted_diff = diff_sq * (mask + 0.05)\n",
    "    \n",
    "    mse = np.mean(weighted_diff)\n",
    "    if mse == 0: return 100.0\n",
    "    return 10 * np.log10(1.0 / mse)\n",
    "\n",
    "results = []\n",
    "all_pred_scores = []\n",
    "all_ids = []\n",
    "\n",
    "video_folders = sorted(os.listdir(TEST_DIR))\n",
    "print(f\"Generating Smart Flow Predictions...\")\n",
    "\n",
    "for folder_name in tqdm(video_folders):\n",
    "    folder_path = os.path.join(TEST_DIR, folder_name)\n",
    "    if not os.path.isdir(folder_path): continue\n",
    "    try: folder_id = int(folder_name)\n",
    "    except ValueError: continue \n",
    "\n",
    "    frame_files = sorted(glob.glob(os.path.join(folder_path, \"*.jpg\")))\n",
    "    video_psnrs = []\n",
    "    \n",
    "    for i in range(len(frame_files)):\n",
    "        # ID Construction\n",
    "        filename = os.path.basename(frame_files[i])\n",
    "        try: frame_id = int(''.join(filter(str.isdigit, filename)))\n",
    "        except ValueError: frame_id = i\n",
    "        all_ids.append(f\"{folder_id}_{frame_id}\")\n",
    "        \n",
    "        if i < NUM_HIS:\n",
    "            video_psnrs.append(None)\n",
    "            continue\n",
    "            \n",
    "        # Input Prep\n",
    "        history = []\n",
    "        for j in range(NUM_HIS):\n",
    "            img = cv2.imread(frame_files[i - NUM_HIS + j])\n",
    "            img = cv2.resize(img, (256, 256))\n",
    "            img = (img / 127.5) - 1.0\n",
    "            history.append(img)\n",
    "        \n",
    "        # Calculate Flow Mask using the LAST frame of history and CURRENT target\n",
    "        # We need un-normalized frames for flow calculation\n",
    "        prev_raw = cv2.imread(frame_files[i-1])\n",
    "        curr_raw = cv2.imread(frame_files[i])\n",
    "        prev_raw = cv2.resize(prev_raw, (256, 256))\n",
    "        curr_raw = cv2.resize(curr_raw, (256, 256))\n",
    "        \n",
    "        flow_mask = get_optical_flow_mask(prev_raw, curr_raw)\n",
    "        \n",
    "        # Predict\n",
    "        inp = np.concatenate(history, axis=2)\n",
    "        inp = np.expand_dims(inp, axis=0)\n",
    "        \n",
    "        # TTA (Double Predict)\n",
    "        pred_normal = ai_brain(inp, training=False)[0].numpy()\n",
    "        inp_flipped = inp[:, :, ::-1, :]\n",
    "        pred_flipped = ai_brain(inp_flipped, training=False)[0].numpy()[:, ::-1, :]\n",
    "        pred_avg = (pred_normal + pred_flipped) / 2.0\n",
    "        \n",
    "        # Smart Scoring\n",
    "        gt = (curr_raw.astype(np.float32) / 127.5) - 1.0\n",
    "        psnr = calculate_smart_psnr(pred_avg, gt, flow_mask)\n",
    "        video_psnrs.append(psnr)\n",
    "\n",
    "    # Normalize & Invert (Same as before)\n",
    "    valid = [x for x in video_psnrs if x is not None]\n",
    "    if not valid: filled = [0.0]*len(video_psnrs)\n",
    "    else:\n",
    "        mx = max(valid)\n",
    "        filled = [x if x is not None else mx for x in video_psnrs]\n",
    "    \n",
    "    smoothed = gaussian_filter1d(filled, sigma=4.0)\n",
    "    all_pred_scores.extend(smoothed)\n",
    "\n",
    "# Global Norm\n",
    "all_scores_arr = np.array(all_pred_scores)\n",
    "reg_scores = (all_scores_arr - all_scores_arr.min()) / (all_scores_arr.max() - all_scores_arr.min())\n",
    "anomaly_scores = 1.0 - reg_scores\n",
    "\n",
    "df = pd.DataFrame({\"Id\": all_ids, \"Predicted\": anomaly_scores})\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"Saved Smart Flow Predictions to {OUTPUT_CSV}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
